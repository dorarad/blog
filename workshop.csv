Timestamp,Email Address,Main Conference / Datasets Track / Workshop? (please specify its name),Title,"Authors (full name, comma separated)",Abstract,key words,Point of contact email address,Image To Represent Paper,"Are you presenting a poster? If so, what's the Poster session date and time? (Format: Dec 1, 17:00-20:00)

[Skip if information is not available and we will contact you close to the conference]","Are you presenting a poster? If so, what's the Poster session number and location? (format: Poster 321, room 123)

[Skip if information is not available and we will contact you close to the conference]","Are you presenting a talk? If so, what's the oral session date and time? (Format: Dec 1, 10:00-13:00)

[Skip if information is not available and we will contact you close to the conference]","Are you presenting a talk? If so, what's the talk session name and location? (format: Generative models, room 123)

[Skip if information is not available and we will contact you close to the conference]","Award Nominations (if any, comma separated)",Link to project website,Link to paper,Link to blog post (if any),"Link to public video (e.g. YouTube, if any)"
11/15/2022 20:02:45,bwlarsen@stanford.edu,(Workshop) Has it Trained Yet? A Workshop for Algorithmic Efficiency in Practical Neural Network Training,Unmasking the Lottery Ticket Hypothesis: Efficient Adaptive Pruning for Finding Winning Tickets,"Mansheej Paul*, Feng Chen*, Brett W. Larsen*, Jonathan Frankle, Surya Ganguli, Gintare Karolina Dziugaite","Modern deep learning involves training costly, highly overparameterized networks, thus motivating the search for sparser networks that require less compute and memory but can still be trained to the same accuracy as the full network (i.e. matching). Iterative magnitude pruning (IMP) is a state of the art algorithm that can find such highly sparse matching subnetworks, known as winning tickets, that can be retrained from initialization or an early training stage. IMP operates by iterative cycles of training, masking a fraction of smallest magnitude weights, rewinding unmasked weights back to an early training point, and repeating. Despite its simplicity, the underlying principles for when and how IMP finds winning tickets remain elusive. In particular, what useful information does an IMP mask found at the end of training convey to a rewound network near the beginning of training? We find that—at higher sparsities—pairs of pruned networks at successive pruning iterations are connected by a linear path with zero error barrier if and only if they are matching. This indicates that masks found at the end of training encodes information about the identity of an axial subspace that intersects a desired linearly connected mode of a matching sublevel set. We leverage this observation to design a simple adaptive pruning heuristic for speeding up the discovery of winning tickets and achieve a 30% reduction in computation time on CIFAR-100. These results make progress toward demystifying the existence of winning tickets with an eye towards enabling the development of more efficient pruning algorithms.","linear mode connectivity, iterative magnitude pruning, loss landscape geometry, lottery ticket hypothesis, sparsity",mansheej@stanford.edu,https://drive.google.com/open?id=1iPz_nFicG52f1Zj0Qx-9XytL4XLDzE-r,"Dec 2, 14:10-15:00",,,,,,https://openreview.net/forum?id=nBRNjUPhWr,,
11/27/2022 11:39:57,yuhuiz@stanford.edu,DistShift Workshop,DrML: Diagnosing and Rectifying Vision Models using Language,"Yuhui Zhang, Jeff Z. HaoChen, Shih-Cheng Huang, Kuan-Chieh Wang, James Zou, Serena Yeung","Recent multi-modal contrastive learning models have demonstrated the ability to learn an embedding space suitable for building strong vision classifiers, by leveraging the rich information in large-scale image-caption datasets. Our work highlights a distinct advantage of this multi-modal embedding space: the ability to diagnose vision classifiers through natural language. The traditional process of diagnosing model behaviors in deployment settings involves labor-intensive data acquisition and annotation. Our proposed method, DrML, can discover high-error data slices, identify influential attributes and further rectify undesirable model behaviors, without requiring any visual data. Through a combination of theoretical explanation and empirical verification, we present conditions under which classifiers trained on embeddings from one modality can be equivalently applied to embeddings from another modality. On a range of image datasets with known error slices, we demonstrate that our method can effectively identify the error slices and influential attributes, and can further use language to rectify failure modes of the classifier.","model diagnosis, multi-modal contrastive learning, vision and language",yuhuiz@stanford.edu,https://drive.google.com/open?id=1q-Yh9oTN0mWSo6_jGvlvVMEUb14s7QGW,,,,,,,https://openreview.net/pdf?id=ZpN2EOEUnr,,
11/4/2022 23:09:58,jniklaus@stanford.edu,ENLSP,BudgetLongformer: Can we Cheaply Pretrain a SotA Legal Language Model From Scratch?,"Joel Niklaus, Daniele Giofre","Pretrained transformer models have achieved state-of-the-art results in many tasks and benchmarks recently. Many state-of-the-art Language Models (LMs), however, do not scale well above the threshold of 512 input tokens. In specialized domains though (such as legal, scientific or biomedical), models often need to process very long text (sometimes well above 10000 tokens). Even though many efficient transformers have been proposed (such as Longformer, BigBird or FNet), so far, only very few such efficient models are available for specialized domains. Additionally, since the pretraining process is extremely costly in general -- but even more so as the sequence length increases -- it is often only in reach of large research labs. One way of making pretraining cheaper is the Replaced Token Detection (RTD) task, by providing more signal during training, since the loss can be computed over all tokens. In this work, we train Longformer models with the efficient RTD task on legal data to showcase that pretraining efficient LMs is possible using much less compute. We evaluate the trained models on challenging summarization tasks requiring the model to summarize long texts to show to what extent the models can achieve good performance on downstream tasks. We find that both the small and base models outperform their baselines on the in-domain BillSum and out-of-domain PubMed tasks in their respective parameter range. We publish our code and models for research purposes.","efficient training, language model, electra, replaced token detection, summarization, legal, longformer",jniklaus@stanford.edu,https://drive.google.com/open?id=1Z-OjS9t0csfY5EUZiN-kJFsEWX9KNEAg,"Dec 2, time tbd","Poster tbd, room tbd",,,,,Still under review,,
11/23/2022 17:29:46,rajsaha@stanford.edu,Federated Learning: Recent Advances and New Challenges (FL-NeurIPS'22),ColRel: Collaborative Relaying for Federated Learning over Intermittently Connected Networks,"Rajarshi Saha, Michal Yemini, Emre Ozfatura, Deniz Gunduz, Andrea Goldsmith","Intermittent connectivity of clients to the parameter server (PS) is a major bottleneck in federated edge learning. It induces a large generalization gap, especially when the local data distribution amongst clients exhibits heterogeneity. To overcome communication blockages between clients and the central PS, we introduce the concept of collaborative relaying (ColRel) wherein the participating clients relay their neighbors' local updates to the PS in order to boost the participation of clients with poor connectivity to the PS. For every communication round, each client initially computes a local consensus of a subset of its neighboring clients' updates and subsequently transmits to the PS, a weighted average of its own update and those of its neighbors'. We optimize these weights to ensure that the global update at the PS is unbiased with minimal variance -- consequently improving the convergence rate. Numerical evaluations on the CIFAR-10 dataset demonstrate that our ColRel-based approach achieves a higher test accuracy over Federated Averaging based benchmarks for learning over intermittently-connected networks.","Federated Learning, Intermittently connected links, Topology-induced variance, Client collaboration, Semi-decentralized, Distributed Mean Estimation",rajsaha@stanford.edu,https://drive.google.com/open?id=1khKl3MLwOg0cXExTSHW2JiabIZl_snjZ,"Dec 2, 11:15 - 12:00 CST","Poster 13, Room 298-299",,,,,https://openreview.net/forum?id=8b0RHdh2Xd0,,
11/7/2022 9:55:15,dilip@cs.stanford.edu,Information-Theoretic Principles in Cognitive Systems Workshop ,On Rate-Distortion Theory in Capacity-Limited Cognition & Reinforcement Learning,"Dilip Arumugam, Mark K. Ho, Noah D. Goodman, Benjamin Van Roy","Throughout the cognitive-science literature, there is widespread agreement that decision-making agents operating in the real world do so under limited information-processing capabilities and without access to unbounded cognitive or computational resources. Prior work has drawn inspiration from this fact and leveraged an information-theoretic model of such behaviors or policies as communication channels operating under a bounded rate constraint. Meanwhile, a parallel line of work also capitalizes on the same principles from rate-distortion theory to formalize capacity-limited decision making through the notion of a learning target, which facilitates Bayesian regret bounds for provably-efficient learning algorithms. In this paper, we aim to elucidate this latter perspective by presenting a brief survey of these information-theoretic models of capacity-limited decision making in biological and artificial agents.","Bounded rationality, Resource-rational analysis, Reinforcement learning, Efficient exploration, Information theory, Bayesian reinforcement learning, Satisficing",dilip@cs.stanford.edu,https://drive.google.com/open?id=1PQ-_fJGx7Kyk6eCefOAsxzmsv0Eju7zV,,,,,,,https://dilipa.github.io/papers/nips22_infocog_workshop_rdt_satisficing.pdf,,
11/9/2022 22:58:03,alexkw@stanford.edu,Learning from Time Series for Health Workshop,Learning Absorption Rates in Glucose-Insulin Dynamics from Meal Covariates,"Ke Alexander Wang, Matthew E. Levine, Jiaxin Shi, Emily Fox","Traditional models of glucose-insulin dynamics rely on heuristic parameterizations chosen to fit observations within a laboratory setting. However, these models cannot describe glucose dynamics in daily life. One source of failure is in their descriptions of glucose absorption rates after meal events. A meal's macronutritional content has nuanced effects on the absorption profile, which is difficult to model mechanistically. In this paper, we propose to learn the effects of macronutrition content from glucose-insulin data and meal covariates.  Given macronutrition information and meal times, we use a neural network to predict an individual's glucose absorption rate. We use this neural rate function as the control function in a differential equation of glucose dynamics, enabling end-to-end training. On simulated data, our approach is able to closely approximate true absorption rates, resulting in better forecast than heuristic parameterizations, despite only observing glucose, insulin, and macronutritional information.  Our work readily generalizes to meal events with higher-dimensional covariates, such as images, setting the stage for glucose dynamics models that are personalized to each individual's daily life. ","time-series, health, diabetes, mechanistic models, differential equations, neural networks, forecasting, glucose-insulin dynamics",alxwang@cs.stanford.edu,https://drive.google.com/open?id=1oCl_liUcUnlkXc3gu-N0VidVSDCZc79f,,,,,,,,,
11/25/2022 21:05:09,brando9@stanford.edu,Meta-learning workshop,The Curse of Low Task Diversity: On the Failure of Transfer Learning to Outperform MAML and Their Empirical Equivalence,"Brando Miranda, Patrick Yu, Yu-Xiong Wang, Sanmi Koyejo","Recently, it has been observed that a transfer learning solution might be all we need to solve many few-shot learning benchmarks -- thus raising important questions about when and how meta-learning algorithms should be deployed. 
In this paper, we seek to clarify these questions by 
1. proposing a novel metric -- the {\it diversity coefficient} -- to measure the diversity of tasks in a few-shot learning benchmark and 
2. by comparing Model-Agnostic Meta-Learning (MAML) and transfer learning under fair conditions (same architecture, same optimizer, and all models trained to convergence).
Using the diversity coefficient, we show that the popular MiniImageNet and CIFAR-FS few-shot learning benchmarks have low diversity. 
This novel insight contextualizes claims that transfer learning solutions are better than meta-learned solutions in the regime of low diversity under a fair comparison. 
Specifically, we empirically find that a low diversity coefficient correlates with a high similarity between transfer learning and MAML learned solutions in terms of accuracy at meta-test time and classification layer similarity (using feature based distance metrics like SVCCA, PWCCA, CKA, and OPD). 
To further support our claim, we find this meta-test accuracy holds even as the model size changes. 
Therefore, we conclude that in the low diversity regime, MAML and transfer learning have equivalent meta-test performance when both are compared fairly.
We also hope our work inspires more thoughtful constructions and quantitative evaluations of meta-learning benchmarks in the future.","meta-learning, transfer learning, maml",brando9@stanford.edu,https://drive.google.com/open?id=1KVecgtJVqCFYaLQLZneaU9ZQ-4gO4Y5P,,,"Dec 3, 3:00-3:15",,,,https://arxiv.org/abs/2208.01545,,https://youtu.be/mM5vllz1hPg
11/14/2022 11:35:05,lnardi@stanford.edu,MetaLearn Workshop,PriorBand: Hyperband + Human Expert Knowledge,"Neeratyoy Mallik*, Carl Hvarfner*, Danny Stoll, Maciej Janowski, Edward Bergman, Mairus Lindauer, Luigi Nardi, Frank Hutter","Hyperparameters of Deep Learning (DL) pipelines are crucial for their performance. While a large number of methods for hyperparameter optimization (HPO) have been developed, they are misaligned with the desiderata of a modern DL researcher. Since often only a few trials are possible in the development of new DL methods, manual experimentation is still the most prevalent approach to set hyperparameters, relying on the researcher’s intuition and cheap preliminary explorations. To resolve this shortcoming of HPO for DL, we propose PriorBand, an HPO algorithm tailored to DL, able to utilize both expert beliefs and cheap proxy tasks. Empirically, we demonstrate the efficiency of PriorBand across a range of DL models and tasks using as little as the cost of 10 training runs and show its robustness against poor expert beliefs and misleading proxy tasks.
","Hyperparameter optimization, Hyperband, Multi-fidelity, Deep learning",lnardi@stanford.edu,https://drive.google.com/open?id=1u8IogNVSotelok8ryiCB41OKIcEZSFSB,,,,,No, https://github.com/automl/mf-prior-exp,https://openreview.net/forum?id=ds21dwfBBH,,
11/7/2022 18:40:44,tailin@cs.stanford.edu,NeurIPS 2022 AI4Science workshop,Learning Controllable Adaptive Simulation for Multi-scale Physics,"Tailin Wu, Takashi Maruyama, Qingqing Zhao, Gordon Wetzstein, Jure Leskovec","Simulating the time evolution of physical systems is pivotal in many scientific and engineering problems. An open challenge in simulating such systems is their multi-scale dynamics: a small fraction of the system is extremely dynamic, and requires very fine-grained resolution, while a majority of the system is changing slowly and can be modeled by coarser spatial scales. Typical learning-based surrogate models use a uniform spatial scale, which needs to resolve to the finest required scale and can waste a huge compute to achieve required accuracy. In this work, we introduce Learning controllable Adaptive simulation for Multi-scale Physics (LAMP) as the first full deep learning-based surrogate model that jointly learns the evolution model and optimizes appropriate spatial resolutions that devote more compute to the highly dynamic regions. LAMP consists of a Graph Neural Network (GNN) for learning the forward evolution, and a GNN-based actor-critic for learning the policy of spatial refinement and coarsening. We introduce learning techniques that optimizes LAMP with weighted sum of error and computational cost as objective, which allows LAMP to adapt to varying relative importance of error vs. computation tradeoff at inference time. We test our method in a 1D benchmark of nonlinear PDEs and a challenging 2D mesh-based simulation. We demonstrate that our LAMP outperforms state-of-the-art deep learning surrogate models with up to 39.3% error reduction, and is able to adaptively trade-off computation to improve long-term prediction error.","adaptive, multi-scale, error vs. computation, controllable, physical simulation",tailin@cs.stanford.edu,https://drive.google.com/open?id=13Ax1l0FacEBijgMtIy-52GuRip6fN1Dx,,,,,,,https://openreview.net/forum?id=PhktEpJHU3,,
11/7/2022 18:42:19,tailin@cs.stanford.edu,NeurIPS 2022 AI4Science Workshop,Learning Efficient Hybrid Particle-continuum Representations of Non-equilibrium N-body Systems," Tailin Wu, Michael Sun, H.G. Jason Chou, Pranay Reddy Samala, Sithipont Cholsaipant, Sophia Kivelson, Jacqueline Yau, Zhitao Ying, E. Paulo Alves, Jure Leskovec, Frederico Fiuza","An important class of multi-scale, non-equilibrium, N-body physical systems deals with an interplay between particle and continuum phenomena. These include hypersonic flow and plasma dynamics, materials science, and astrophysics. Hybrid solvers that combine particle and continuum representations could provide an efficient framework to model these systems. However, the coupling between these two representations has been a key challenge, which is often limited to inaccurate or incomplete prescriptions. In this work, we introduce a method for Learning Hybrid Particle-Continuum (LHPC) models from the data of first-principles particle simulations. LHPC analyzes the local velocity-space particle distribution function and separates it into near-equilibrium (thermal) and far-from-equilibrium (non-thermal) components. The most computationally-intensive particle solver is used to advance the non-thermal particles, whereas a neural network solver is used to efficiently advance the thermal component using a continuum representation. Most importantly, an additional neural network learns the particle-continuum coupling: the dynamical exchange of mass, momentum, and energy between the particle and continuum representations. Training of the different neural network components is done in an integrated manner to ensure global consistency and stability of the LHPC model. We demonstrate our method in an intense laser-plasma interaction problem involving highly nonlinear, far-from-equilibrium dynamics associated with the coupling between electromagnetic fields and multiple particle species. More efficient modeling of these interactions is critical for the design and optimization of compact accelerators for material science and medical applications. Our method achieves an important balance between accuracy and speed: LHPC is 8 times faster than a classical particle solver and achieves up to 6.8-fold reduction of long-term prediction error for key quantities of interest compared to deep-learning baselines using uniform representations.","multi-scale, hybrid representation, particle-continuum, n-body, plasma",tailin@cs.stanford.edu,https://drive.google.com/open?id=1SWcfjnrpo0ikV5dk7EtMENh5F-ydr7Xa,,,,,,,https://openreview.net/forum?id=Rd68eTARk4,,
11/14/2022 22:47:57,rtaori@stanford.edu,NeurIPS 2022 Workshop on Distribution Shifts (DistShift),Data Feedback Loops: Model-driven Amplification of Dataset Biases,"Rohan Taori, Tatsu Hashimoto","Datasets scraped from the internet have been critical to the successes of large-scale machine learning. Yet, this very success puts the utility of future internet-derived datasets at potential risk, as model outputs begin to replace human annotations as a source of supervision. In this work, we first formalize a system where interactions with one model are recorded as history and scraped as training data in the future. We then analyze its stability over time by tracking changes to a test-time bias statistic (e.g. gender bias of model predictions). We find that the degree of bias amplification is closely linked to whether the model's outputs behave like samples from the training distribution, a behavior which we characterize and define as consistent calibration. Experiments in three conditional prediction scenarios - image classification, visual role-labeling, and language generation - demonstrate that models that exhibit a sampling-like behavior are more calibrated and thus more stable. Based on this insight, we propose an intervention to help calibrate and stabilize unstable feedback systems.","feedback loops, bias amplification, deep learning, self-supervised learning, CV, NLP",rtaori@stanford.edu,https://drive.google.com/open?id=1AOwmGYH3roKNbREquyzxYW43GxZkt6gs,"Dec 3, 1-2:30pm",Room 388 - 390,"Dec 3, 3:20-3:30pm","DistShift Workshop, Room 388 - 390",Spotlight at the DistShift workshop,https://tinyurl.com/data-feedback,https://arxiv.org/abs/2209.03942,,
11/23/2022 1:18:29,jiaxins@stanford.edu,OPT 2022: Optimization for Machine Learning (NeurIPS 2022 Workshop),A Finite-Particle Convergence Rate for Stein Variational Gradient Descent,"Jiaxin Shi, Lester Mackey","We provide a first finite-particle convergence rate for Stein variational gradient descent (SVGD). Specifically, whenever the target distribution is sub-Gaussian with a Lipschitz score, SVGD with n particles and an appropriate step size sequence drives the kernel Stein discrepancy to zero at an order 1/sqrt(log log n) rate. We suspect that the dependence on n can be improved, and we hope that our explicit, non-asymptotic proof strategy will serve as a template for future refinements.","Sampling, Stein Variational Gradient Descent, Convergence rate, Non-asymptotic analysis",jiaxins@stanford.edu,https://drive.google.com/open?id=1BlCzkzMl2GVIXGFlOT5Ad2hTMtUXwVgC,"Dec 3, 3:50-4:50","Poster Session 2, Room 298 - 299",N/A,N/A,,,https://arxiv.org/abs/2211.09721,,
11/22/2022 23:05:21,mishkin@stanford.edu,OPT Workshop on Optimization for Machine Learning,The Solution Path of the Group Lasso,"Aaron Mishkin, Mert Pilanci","We prove continuity of the solution path for the group lasso, a popular method of computing group-sparse models. Unlike the more classical lasso method, the group lasso solution path is non-linear and cannot be evaluated algorithmically. To circumvent this, we first characterize the group lasso solution set and then show how to construct an implicit function for the min-norm path. We prove our implicit representation is continuous almost everywhere and extend this to continuity everywhere when the group lasso solution is unique. These results can be viewed as extending solution path analyses from the lasso to the group lasso and imply that grid-search is a sensible approach to hyper-parameter selection. Our work applies to linear models as well as convex reformulations of neural networks and provides new tools for understanding solution paths of shallow ReLU models.","regularization path, lasso, group lasso, sparsity, optimization",mishkin@stanford.edu,https://drive.google.com/open?id=1rfSwS6jWAMFBNEJqwPVGaQ4quk3aSq3e,,,,,,,,,
11/17/2022 1:56:47,nikhilvr@stanford.edu,Synthetic Data for Empowering ML Research,Federated Learning on Patient Data for Privacy-Protecting Polycystic Ovary Syndrome Treatment,"Lucia Morris*, Tori Qiu*, Nikhil Raghuraman*","The field of women’s endocrinology has trailed behind data-driven medical solutions, largely due to concerns over the privacy of patient data. Valuable datapoints about hormone levels or menstrual cycling could expose patients who suffer from comorbidities or terminate a pregnancy, violating their privacy. We explore the application of Federated Learning (FL) to predict the optimal drug for patients with polycystic ovary syndrome (PCOS). PCOS is a serious hormonal disorder impacting millions of women worldwide, yet it’s poorly understood and its research is stunted by a lack of patient data. We demonstrate that a variety of FL approaches succeed on a synthetic PCOS patient dataset. Our proposed FL models are a tool to access massive quantities of diverse data and identify the most effective treatment option while providing PCOS patients with privacy guarantees. Our code is open-sourced at https://github.com/toriqiu/fl-pcos.","Federated learning, privacy, polycystic ovary syndrome",nikhilvr@stanford.edu,https://drive.google.com/open?id=1CMJ-PeM81oYSsack9rGj6XDlq-WVgS3X,,,,,,,https://www.researchgate.net/publication/365174780_Federated_Learning_on_Patient_Data_for_Privacy-Protecting_Polycystic_Ovary_Syndrome_Treatment,,
11/21/2022 7:50:31,am2@stanford.edu,WiML Workshop,Kernel Density Bayesian Inverse Reinforcement Learning,"Aishwarya Mandyam, Didong Li, Diana Cai, Andrew Jones, Barbara Engelhardt","Inverse reinforcement learning (IRL) is a powerful framework for learning the reward function of an agent by observing its behavior, but IRL algorithms that infer point estimates of the reward function can be misleading because there may be several reward functions that capture an agent's behavior equally well. A Bayesian approach to IRL models a distribution over possible reward functions that can explain the set of observations, alleviating the shortcomings of learning a single point estimate. Several existing Bayesian approaches for IRL use a $Q$-value function, estimated using $Q$-learning, in place of the likelihood function. However, the resulting posterior is computationally intensive to calculate, has few theoretical guarantees, and the $Q$-value function is often a poor approximation for the true likelihood. We introduce kernel density Bayesian IRL (KD-BIRL), which uses conditional kernel density estimation to directly approximate the likelihood function, leading to a more efficient approach to Bayesian IRL. 
We prove that the resulting posterior distribution contracts to the true, data generating reward function as the sample size increases, providing a flexible and efficient framework that is applicable to environments with complex state spaces. We demonstrate KD-BIRL's computational benefits and ability to represent uncertainty in the recovered reward function through a series of experiments in Gridworld environments and on a healthcare task.","inverse reinforcement learning, bayesian statistics",am2@stanford.edu,https://drive.google.com/open?id=1X41wUoO1zJXXT_oUhKJUleK4vJPDGJFR,"Nov 28, 4:30-6:30",Not sure yet,,,,,https://aishwarya-rm.github.io/data/kdbirl.pdf,,
11/4/2022 1:08:54,ransalu@stanford.edu,Workshop,5th Robot Learning Workshop: Trustworthy Robotics,Ransalu Senanayake,"Machine learning (ML) has been one of the premier drivers of recent advances in robotics research and has made its way into impacting several real-world robotic applications in unstructured and human-centric environments, such as transportation, healthcare, and manufacturing. At the same time, robotics has been a key motivation for numerous research problems in artificial intelligence research, from efficient algorithms to robust generalization of decision models. However, there are still considerable obstacles to fully leveraging state-of-the-art ML in real-world robotics applications. For capable robots equipped with ML models, guarantees on the robustness and additional analysis of the social implications of these models are required for their utilization in real-world robotic domains that interface with humans (e.g. autonomous vehicles, and tele-operated or assistive robots).

To support the development of robots that are safely deployable among humans, the field must consider trustworthiness as a central aspect in the development of real-world robot learning systems. Unlike many other applications of ML, the combined complexity of physical robotic platforms and learning-based perception-action loops presents unique technical challenges. These challenges include concrete technical problems such as very high performance requirements, explainability, predictability, verification, uncertainty quantification, and robust operation in dynamically distributed, open-set domains. Since robots are developed for use in human environments, in addition to these technical challenges, we must also consider the social aspects of robotics such as privacy, transparency, fairness, and algorithmic bias. Both technical and social challenges also present opportunities for robotics and ML researchers alike. Contributing to advances in the aforementioned sub-fields promises to have an important impact on real-world robot deployment in human environments, building towards robots that use human feedback, indicate when their model is uncertain, and are safe to operate autonomously in safety-critical settings such as healthcare and transportation.

This year’s robot learning workshop aims at discussing unique research challenges from the lens of trustworthy robotics. We adopt a broad definition of trustworthiness that highlights different application domains and the responsibility of the robotics and ML research communities to develop “robots for social good.” Bringing together experts with diverse backgrounds from the ML and robotics communities, the workshop will offer new perspectives on trust in the context of ML-driven robot systems.","Trustworthy AI, Robotics",ransalu@stanford.edu,https://drive.google.com/open?id=1Xbe_XBxPe8zYvpkmWkIJX3MAW1Tdkvt0,"Dec 9, 07:00-1900 PST",Virtual,"Dec 9, 07:00-1900 PST",Virtual,,http://robot-learning.ml/,http://robot-learning.ml/,,
11/22/2022 19:30:58,helenav@stanford.edu,Workshop on Human-Centered AI,Generation Probabilities are Not Enough: Improving Error Highlighting for AI Code Suggestions,"Helena Vasconcelos, Gagan Bansal, Adam Fourney, Q.Vera Liao, Jennifer Wortman Vaughan","Large-scale generative models are increasingly being used in tooling applications. As one prominent example, code generation models recommend code completions within an IDE to help programmers author software. However, since these models are imperfect, their erroneous recommendations can introduce bugs or even security vulnerabilities into a code base if not overridden by a human user. In order to override such errors, users must first detect them. One method of assisting this detection has been highlighting tokens with low generation probabilities. We also propose another method, predicting the tokens people are likely to edit in a generation. Through a mixed-methods, pre-registered study with N = 30 participants, we find that the edit model highlighting strategy results in significantly faster task completion time, significantly more localized edits, and was strongly preferred by participants.","Generative models, uncertainty, human-AI interaction",helenav@stanford.edu,https://drive.google.com/open?id=10qBoGSOQcgQoT7OHmOi4lpQxEYxWULeC,,,,,,,,,